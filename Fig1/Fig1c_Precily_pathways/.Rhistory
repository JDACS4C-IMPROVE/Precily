library(purrr)
library(purr)
ll <- list(A,B,C)
reduce(ll,`+`) / length(ll)
View(A)
View(B)
View(C)
(2+6+8)/3
install.packages("h2o", "3.36.0.3")
data = read.csv("C:\\Users\\chawl\\OneDrive\\Desktop\\P1-05-Drug_disease.txt",sep="\t",header = F)
View(data)
head(data[,1:6,])
head(data[1:6,])
str_extract(string = data$V1, pattern = "[^_]"))
str_extract(string = data$V1, pattern = "[^_]")
listr_extract(string = data$V1, pattern = "[^_]")
library(stringi)
library(stringr)
listr_extract(string = data$V1, pattern = "[^_]")
str_extract(string = data$V1, pattern = "[^_]")
data = read.csv("C:\\Users\\chawl\\OneDrive\\Desktop\\P1-05-Drug_disease.txt",sep="\t",header = F)
View(data)
pos = which(data$V1 = " ")
pos = which(data$V1 == " ")
pos = which(data$V1 == "")
print("none")
for (i in 1:nrow(data)){
if (data[i,]=="")
print(i)
else
print("none")
}
i
data = read.csv("C:\\Users\\chawl\\OneDrive\\Desktop\\Book2.csv",sep=",",header = F)
View(data)
data = data[,-c(2,3)]
data = read.csv("C:\\Users\\chawl\\OneDrive\\Desktop\\Book2.csv",sep=",",header = F)
data = as.data.frame(data[,-c(2,3)]0
data = as.data.frame(data[,-c(2,3)])
data = read.csv("C:\\Users\\chawl\\OneDrive\\Desktop\\P1-05-Drug_disease.txt",sep="\t",header = F)
#ind = grep("Prostate cancer",data[,1], value = TRUE)
li = list()
for (i in 1:nrow(data)){
if (!data[i,]=="")
print(i)
else
print("none")
}
li = list()
for (i in 1:nrow(data)){
if (!data[i,]=="")
li = paste(data[i,])
}
li = list()
for (i in 1:nrow(data)){
if (!data[i,]=="")
li = paste(data[i,])
}
li
data = read.csv("C:\\Users\\chawl\\OneDrive\\Desktop\\P1-05-Drug_disease.txt",sep="\t",header = F)
View(data)
li = list()
for (i in 1:nrow(data)){
if (!data[i,]=="")
li = (data[i,])
}
View(li)
li = list()
for (i in 1:nrow(data)){
if (!data[i,]=="")
li[[i]] = (data[i,])
}
View(li)
li[[1]]
View(data)
data = read.csv("C:\\Users\\chawl\\OneDrive\\Desktop\\Book2.csv",sep="\t",header = F)
View(data)
data = read.csv("C:\\Users\\chawl\\OneDrive\\Desktop\\Book2.csv",header = F)
View(data)
data = as.data.frame(data[,-c(2,3)])
View(data)
pos = which(data[,1] =="")
pos = which(data[,1] ==" ")
test <- aggregate(data))
test <- aggregate(data))
test <- aggregate(data)
test <- aggregate(data,by= " ")
data = read.csv("C:\\Users\\chawl\\OneDrive\\Desktop\\P1-05-Drug_disease.txt",sep="\t",header = F)
View(data)
x= aggregate(V2~V2, data = , paste, collapse=",")
x= aggregate(V2~V2, data , paste, collapse=",")
View(x)
x= aggregate(V2~V2, data , paste, collapse=" ")
View(data)
data = read.csv("C:\\Users\\chawl\\OneDrive\\Desktop\\Book2.csv",header = F)
data = as.data.frame(data[,-c(2,3)])
View(data)
x=split.data.frame(data)
?split.data.frame
x=split.data.frame(data,f= " ")
View(x)
d = t(data)
View(d)
x=split.data.frame(d, " ")
View(x)
View(d)
d = read.csv('C:\\Users\\chawl\\Downloads\\ATTX1.meta.data_2021-01-22.txt',sep="\t")
View(d)
table(d$ResponseTypeA)
metadata = read.csv('C:\\Users\\chawl\\Downloads\\ATTX1.meta.data_2021-01-22.txt',sep="\t")
table(metadata$ResponseTypeA)
5+11
36+15
install.packages("rcdk")
library(rcdk)
install.packages("rJava")
library(rcdk)
library(rJava)
system("java -version")
packageVersion("rjava")
install.packages("rJava")
library(rJava)
library(rJava)
install.packages("rJava")
library(rJava)
Sys.setenv(JAVA_HOME='C:\Program Files (x86)\Java\jre1.8.0_333\bin')
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre1.8.0_333\bin')
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre1.8.0_333\\bin')
library(rJava)
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre1.8.0_333\\legal\\jdk')
library(rJava)
install.packages("rJava")
library(rJava)
packageVersion("h2o")
install.packages("h2o")
# Load library
library(h2o)
# start h2o cluster
invisible(h2o.init())
# convert data as h2o type
train_h = as.h2o(train)
test_h = as.h2o(test)
# set label type
y = 'Species'
pred = setdiff(names(train), y)
#convert variables to factors
train[,y] = as.factor(train[,y])
test[,y] = as.factor(test[,y])
# Run AutoML for 20 base models
aml = h2o.automl(x = pred, y = y,
training_frame = train_h,
max_models = 2,
seed = 1,
max_runtime_secs = 20
)
library(h2o)
# Start the H2O cluster (locally)
h2o.init()
# Import a sample binary outcome train/test set into H2O
train <- h2o.importFile("https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv")
test <- h2o.importFile("https://s3.amazonaws.com/erin-data/higgs/higgs_test_5k.csv")
# Identify predictors and response
y <- "response"
x <- setdiff(names(train), y)
# For binary classification, response should be a factor
train[, y] <- as.factor(train[, y])
test[, y] <- as.factor(test[, y])
# Run AutoML for 20 base models
aml <- h2o.automl(x = x, y = y,
training_frame = train,
max_models = 2,
seed = 1)
aml@leader
doim(traub)
doim(train)
dim(train)
table(Train[,29])
table(train[,29])
View(train)
train
table(train[,1])
table(as.data.frame(train[,1])
)
aml@leader
setwd("C:\\Users\\chawl\\OneDrive\\Documents\\GitHub\\NKCell\\Figure2\\Fig2b")
##loading libraries
library(Seurat)
library(viridis)
library(RColorBrewer)
library(pheatmap)
#####Processing single cell gene expression data from run1
data <- read.csv("Breast_cancer_run1.csv",sep=",",header = T,stringsAsFactors = F,row.names = 1)
expression_matrix = as.matrix(data[,5:ncol(data)])
gnames = as.matrix(data[,1])
rownames(expression_matrix) = gnames
expression_matrix = expression_matrix[which(rowSums(expression_matrix)>0),]
expression_matrix = expression_matrix[,-c(63,68,96)]
colnames(expression_matrix) = gsub('(.*)_\\w+', '\\1',colnames(expression_matrix))
meta1 = read.csv("Run1_cell_metadata.csv",sep=",",header=T,stringsAsFactors = F,row.names = 1,check.names = F,strip.white = T)
mt1 = meta1[colnames(expression_matrix),]
pos = which(mt1[,6]==0)
mt1 = mt1[-pos,]
expression_matrix = expression_matrix[,-pos]
genes = read.table("protein_coding_gene_list.txt",sep="\t")
pos1 = which(rownames(expression_matrix) %in% genes[,1])
expression_matrix = as.matrix(expression_matrix[pos1,])
exprs_Genes = apply(expression_matrix, 1, function(x) sum(x > 5)) >= 10
pos = which(colSums(expression_matrix)>2000)
expression_matrix = expression_matrix[exprs_Genes,pos]
#####Processing single cell gene expression data from run2
data1 <- read.csv("Breast_cancer_run2.csv",sep=",",header = T,stringsAsFactors = F,row.names = 1,strip.white=T)
expression_matrix1 = as.matrix(data1[,5:ncol(data1)])
gnames1 = as.matrix(data1[,1])
rownames(expression_matrix1) = gnames1
expression_matrix1 = expression_matrix1[which(rowSums(expression_matrix1)>0),]
expression_matrix1 = expression_matrix1[,-c(32,49,121)]
colnames(expression_matrix1) = gsub('(.*)_\\w+', '\\1',colnames(expression_matrix1))
genes = read.table("protein_coding_gene_list.txt",sep="\t")
pos1 = which(rownames(expression_matrix1) %in% genes[,1])
expression_matrix1 = as.matrix(expression_matrix1[pos1,])
exprs_Genes = apply(expression_matrix1, 1, function(x) sum(x > 5)) >= 10
pos = which(colSums(expression_matrix1)>2000)
expression_matrix1 = expression_matrix1[exprs_Genes,pos]
meta2 = read.table("Run2_cell_metadata.csv",sep=",",header=T,stringsAsFactors = F,row.names = 1,check.names = F,strip.white = T)
rownames(meta2) = gsub('(.*)_\\w+', '\\1',rownames(meta2))
mt2 = meta2[colnames(expression_matrix1),]
pos = which(mt2[,6]==0)
mt2 = mt2[-pos,]
expression_matrix1 = expression_matrix1[,-pos]
colnames(mt1) = c("chip","Run","Selection","Tumor","NK","Final")
colnames(mt2) = c("chip","Run","Selection","Tumor","NK","Final")
labels = rbind((mt1),(mt2))
m1 = as.matrix(paste(mt1$Selection,mt1$Final,sep="_"))
rownames(m1) = rownames(m1)
pos1 = which(m1[,1]=="TU-NK_TU")
expression_matrix = expression_matrix[,-pos1]
m2 = as.matrix(paste(mt2$Selection,mt2$Final,sep="_"))
rownames(m2) = rownames(m2)
pos2 = which(m2[,1]=="TU-NK_TU")
expression_matrix1 = expression_matrix1[,-pos2]
#Breast_cancer_run1
df1 <- CreateSeuratObject(expression_matrix, project = "Breast_cancer_run_1", min.cells = 5)
df1@meta.data$stim <- "Run1"
#Breast_cancer_run2
df2 <- CreateSeuratObject(expression_matrix1, project = "Breast_cancer_run_2", min.cells = 5)
df2@meta.data$stim <- "Run2"
objects = list()
objects[[1]] = df1
objects[[2]] = df2
for (i in 1:length(objects)) {
objects[[i]] <- NormalizeData(objects[[i]], verbose = FALSE)
objects[[i]] <- FindVariableFeatures(objects[[i]], selection.method = "vst",
verbose = FALSE)
}
anchors <- FindIntegrationAnchors(object.list = objects, dims = 1:30,k.filter = 100)
combined <- IntegrateData(anchorset = anchors, dims = 1:30)
DefaultAssay(combined) <- "integrated"
#Visualization and Clustering
combined <- ScaleData(combined, verbose = FALSE)
combined <- RunPCA(combined, npcs = 30, verbose = FALSE)
combined <- RunUMAP(combined, reduction = "pca", dims = 1:30)
combined <- FindNeighbors(combined, reduction = "pca", dims = 1:30)
combined <- FindClusters(combined, resolution = 0.5)
exp = as.matrix(combined@assays$integrated@data)
###Computing correlation between gene expression profiles of doublets and distance of doublets
dis = read.table("Run1_Run2_distance_info.csv",sep=",",header=T,stringsAsFactors = F,row.names = 1)
rownames(dis)[72:113] = gsub('(.*)_\\w+', '\\1',rownames(dis)[72:113])
dis = dis[,3:ncol(dis)]
pos = which(colnames(exp) %in% rownames(dis))
exp = exp[,pos]
dis <- dis[colnames(exp),,drop=FALSE]
exp = as.matrix(t(exp))
dis = as.matrix((dis))
cor = cor(exp,dis,method="pearson")
getwd()
write.csv(cor,file="C:/Users/chawl/OneDrive/Documents/Fig2b_Correlation_file.csv")
quantile(cor, probs = seq(0, 1, by= 0.1)) # decile
hist(cor)
quantile(cor, probs = seq(0, 0.98)) # decile
quantile(cor, probs = (0.98)) # decile
quantile(cor, probs = (0.99)) # decile
quantile(cor, probs = (0.98)) # decile
quantile(cor, probs = 0.988)
quantile(cor, probs = 0.99)
quantile(cor, probs = 0.99.9)
quantile(cor, probs = 0.999)
quantile(cor, probs = 0.987)
quantile(cor, probs = 0.988)
quantile(cor, probs = 0.989)
quantile(cor, probs = 0.99)
x1 = c(1,5,6,8)
x2 = c(3,5,6,8)
cor.test(x1,x2)
?t.test
?stat_cor
library(ggpubr)
?stat_cor
setwd("D:\\Fig1d_meterics_on_validation")
#############Validation sets
##Loading validation  dataset1
val1= read.csv("Val_Set_30_1.csv",sep=",",header=T,stringsAsFactors = F)
dim(val1)
dim(val2)
#############Validation sets
##Loading validation  dataset1
val1= read.csv("Val_Set_30_2.csv",sep=",",header=T,stringsAsFactors = F)
dim(val1)
#############Validation sets
##Loading validation  dataset1
val1= read.csv("Val_Set_30_3.csv",sep=",",header=T,stringsAsFactors = F)
dim(val1)
#############Validation sets
##Loading validation  dataset1
val1= read.csv("Val_Set_30_4.csv",sep=",",header=T,stringsAsFactors = F)
dim(val1)
#############Validation sets
##Loading validation  dataset1
val1= read.csv("Val_Set_30_5.csv",sep=",",header=T,stringsAsFactors = F)
dim(val1)
setwd("D:\\PrecOnco_codes_figurewise\\Fig1\\Fig1c\\Fig1c_Precily_pathways")
##Loading libraries
library(keras)
test = read.csv("Test_Set.csv",sep= ",")
drugs = unique(test$X1)
correlation = list()
for (i in unique(drugs)){
pos = which(test$X1==i)
test1 = test[pos,]
testd = as.matrix(test1[,3:1431])
IC50 = test1[,1432]
##loading models
model1 = load_model_hdf5("Model1.hdf5")
model2 = load_model_hdf5("Model2.hdf5")
model3 = load_model_hdf5("Model3.hdf5")
model4 = load_model_hdf5("Model4.hdf5")
model5 = load_model_hdf5("Model5.hdf5")
##Making predictions
prediction1=model1 %>% predict(testd)
prediction2=model2 %>% predict(testd)
prediction3=model3 %>% predict(testd)
prediction4=model4 %>% predict(testd)
prediction5=model5 %>% predict(testd)
##Averaging out predictions
predictions = apply(cbind.data.frame(prediction1,prediction2,prediction3,prediction4,prediction5),1,mean)
correlation[[i]] = cor(predictions, IC50)
}
cor = do.call(rbind,correlation)
View(cor)
setwd("D:\\PrecOnco_codes_figurewise\\Fig1\\Fig1c\\Fig1c_Elasticnet_pathways")
##loading libraries
library(caret)
library(ggpubr)
library(glmnet)
##loading models
x=load("Pathways_model_ElasticNet_1.RData")
model1= get(x)
x=load("Pathways_model_ElasticNet_2.RData")
model2= get(x)
x=load("Pathways_model_ElasticNet_3.RData")
model3= get(x)
x=load("Pathways_model_ElasticNet_4.RData")
model4= get(x)
x=load("Pathways_model_ElasticNet_5.RData")
model5= get(x)
test= read.csv("Test_Set.csv",sep=",",header=T,stringsAsFactors = F)
drugs = unique(test$X1)
correlation = list()
for (i in unique(drugs)){
pos = which(test$X1==i)
test1 = test[pos,]
xtest = as.matrix(test1[,3:1431])
IC50 = test1[,1432]
##predictions
prediction1 = predict(model1, xtest)
prediction2 = predict(model2, xtest)
prediction3 = predict(model3, xtest)
prediction4 = predict(model4, xtest)
prediction5 = predict(model5, xtest)
predictions = apply(cbind.data.frame(prediction1,prediction2,prediction3,prediction4,prediction5),1,mean)
correlation[[i]] = cor(predictions, IC50)
}
cor = do.call(rbind,correlation)
cor
###loading predictied and actual data
Test = read.csv("Test_predictions.csv",sep=",",header = T,stringsAsFactors = F,row.names = 1,check.names = F)
ob = read.csv("Cellline_Drugs_IC50_test.csv",sep=",",header = T,stringsAsFactors = F,row.names = 1,check.names = F)
###Computing correlation
corr =list()
for (i in 1:ncol(Test)){
df = cbind(Test[,i],ob[,i])
df = na.omit(df)
corr[[i]] = cor(df[,1],df[,2])
}
setwd("D:\\PrecOnco_codes_figurewise\\Fig1\\Fig1c\\cadrres_sc")
###loading predictied and actual data
Test = read.csv("Test_predictions.csv",sep=",",header = T,stringsAsFactors = F,row.names = 1,check.names = F)
ob = read.csv("Cellline_Drugs_IC50_test.csv",sep=",",header = T,stringsAsFactors = F,row.names = 1,check.names = F)
###Computing correlation
corr =list()
for (i in 1:ncol(Test)){
df = cbind(Test[,i],ob[,i])
df = na.omit(df)
corr[[i]] = cor(df[,1],df[,2])
}
###loading predictied and actual data
Test = read.csv("Test_predictions.csv",sep=",",header = T,stringsAsFactors = F,row.names = 1,check.names = F)
ob = read.csv("Cellline_Drugs_IC50_test.csv",sep=",",header = T,stringsAsFactors = F,row.names = 1,check.names = F)
###Computing correlation
corr =list()
for (i in 1:ncol(Test)){
df = cbind(Test[,i],ob[,i])
df = na.omit(df)
corr[[i]] = cor(df[,1],df[,2])
}
correlation = do.call(rbind,corr)
View(correlation)
setwd("D:\\PrecOnco_codes_figurewise\\Fig1\\Fig1c\\Fig1c_Elasticnet_genes")
##loading libraries
library(caret)
library(glmnet)
##loading models
x=load("Model_enet_1.RData")
model1= get(x)
x=load("Model_enet_2.RData")
model2= get(x)
x=load("Model_enet_3.RData")
model3= get(x)
x=load("Model_enet_4.RData")
model4= get(x)
x=load("Model_enet_5.RData")
model5= get(x)
load("Test_set.Rdata")
drugs = unique(Test_set$drug_name)
correlation = list()
for (i in unique(drugs)){
pos = which(Test_set$drug_name==i)
test1 = Test_set[pos,]
xtest = as.matrix(test1[,3:602])
IC50 = test1[,603]
##Predictions
prediction1 = predict(model1, xtest)
prediction2 = predict(model2, xtest)
prediction3 = predict(model3, xtest)
prediction4 = predict(model4, xtest)
prediction5 = predict(model5, xtest)
predictions = apply(cbind.data.frame(prediction1,prediction2,prediction3,prediction4,prediction5),1,mean)
correlation[[i]] = cor(predictions, IC50)
}
cor = do.call(rbind,correlation)
View(cor)
setwd("D:\\PrecOnco_codes_figurewise\Fig1\\Fig1c\\Fig1c_Precily_genes")
setwd("D:\\PrecOnco_codes_figurewise\\Fig1\\Fig1c\\Fig1c_Precily_genes")
##Loading libraries
library(keras)
library(tidyverse)
library(pheatmap)
library(data.table)
library(caret)
test= read.csv("Test_data.csv",sep=",",header=T,stringsAsFactors = F)
drugs = unique(test$X1)
correlation = list()
for (i in unique(drugs)){
pos = which(test$X1==i)
test1 = test[pos,]
testd = as.matrix(test1[,3:602])
IC50 = test1[,603]
##loading models
model1 = load_model_hdf5("Model1.hdf5")
model2 = load_model_hdf5("Model2.hdf5")
model3 = load_model_hdf5("Model3.hdf5")
model4 = load_model_hdf5("Model4.hdf5")
model5 = load_model_hdf5("Model5.hdf5")
##Making predictions
prediction1=model1 %>% predict(testd)
prediction2=model2 %>% predict(testd)
prediction3=model3 %>% predict(testd)
prediction4=model4 %>% predict(testd)
prediction5=model5 %>% predict(testd)
##Averaging out predictions
predictions = apply(cbind.data.frame(prediction1,prediction2,prediction3,prediction4,prediction5),1,mean)
correlation[[i]] = cor(predictions, IC50)
}
cor = do.call(rbind,correlation)
View(cor)
setwd("D:\\PrecOnco_codes_figurewise\\Fig1\\Fig1c\\Fig1c_Precily_pathways")
##Loading libraries
library(keras)
test = read.csv("Test_Set.csv",sep= ",")
drugs = unique(test$X1)
correlation = list()
for (i in unique(drugs)){
pos = which(test$X1==i)
test1 = test[pos,]
testd = as.matrix(test1[,3:1431])
IC50 = test1[,1432]
##loading models
model1 = load_model_hdf5("Model1.hdf5")
model2 = load_model_hdf5("Model2.hdf5")
model3 = load_model_hdf5("Model3.hdf5")
model4 = load_model_hdf5("Model4.hdf5")
model5 = load_model_hdf5("Model5.hdf5")
##Making predictions
prediction1=model1 %>% predict(testd)
prediction2=model2 %>% predict(testd)
prediction3=model3 %>% predict(testd)
prediction4=model4 %>% predict(testd)
prediction5=model5 %>% predict(testd)
##Averaging out predictions
predictions = apply(cbind.data.frame(prediction1,prediction2,prediction3,prediction4,prediction5),1,mean)
correlation[[i]] = cor(predictions, IC50)
}
cor = do.call(rbind,correlation)
